---
title: "Package functions"
author: "Fonti Kar"
date: "2023-04-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preamble

This document maps out the key steps for converting a `.csv` data file into a Darwin Core XML file. These steps will become eventual functions for this R package. The below is a minimal product (no multimedia and mandatory fields/data only)

## Packages/dependencies we need

```{r}
pacman::p_load(tidyverse, here, skimr, janitor)
```

## Example data

I retrieved some example data from [Dyrad](https://datadryad.org/stash/dataset/doi:10.5061%2Fdryad.j9kd51cgr), the respective publication found [here](https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.16501). This study looks like compiled unpublished and unpublished as well collected field data e.g ("A. Westerband" in References field are field collected and presumably unpublished). 

1. Create a folder within the package and name it 'ignore'. This folder is not detected by git and will not be pushed to the repo.
2. Download the zip folder and unzip into `ignore/`.
3. Save the enclosed `.xlsx` file as a `.csv` (manual step)
```{r}
# Read in data
westerband_2022 <- readr::read_csv(here("ignore/doi_10.5061_dryad.j9kd51cgr__v4/Westerband_2022_GCB_DRYAD.csv"))

#Preview
dplyr::glimpse(westerband_2022)
skimr::skim(westerband_2022)
```

Generate some random dates

```{r}
westerband_2022 <- westerband_2022 |> 
  mutate(Collection_date = sample(seq(as.Date('2022/01/01'), as.Date('2023/01/01'), by="day"), nrow(westerband_2022), replace = TRUE))

# write_csv(westerband_2022, here("data/westerband_2022_wdate.csv"))

# Testing what happens with readr::read_csv when you read in a .csv that contains dates. Does it parse as string? 
westerband_2022_wdate <- read_csv(here("data/westerband_2022_wdate.csv"))

glimpse(westerband_2022_wdate) # Yes it guesses the date since it is formatted as yyyy-mm-dd

# What if dates are in non-POSIT formats? See # Checking dates
```

### 1) Assign a unique identifier

```{r}
# https://samfirke.com/2018/08/22/generating-unique-ids-using-r/
create_unique_ids <- function(n, seed_no = 1, char_len = 5){
  set.seed(seed_no)
  pool <- c(letters, LETTERS, 0:9)
  
  res <- character(n) # pre-allocating vector is much faster than growing it
  for(i in seq(n)){
    this_res <- paste0(sample(pool, char_len, replace = TRUE), collapse = "")
    while(this_res %in% res){ # if there was a duplicate, redo
      this_res <- paste0(sample(pool, char_len, replace = TRUE), collapse = "")
    }
      res[i] <- this_res
  }
  res
}

westerband_2022_wdate |> 
  mutate(occurrenceID = create_unique_ids(nrow(westerband_2022))) 
```


### 2) Identify relevant columns

Relying on the ALA [data ingestion documentation](https://support.ala.org.au/support/solutions/articles/6000261427-sharing-a-dataset-with-the-ala) here to choose relevant columns

#### a - Species name

```{r}
potential_names <- c("species",  "SPECIES",
                     "name", "NAME",
                     "species_name", "speciesName", "SPECIES_NAME",
                     "scientific_name", "scientificName", "SCIENTIFIC_NAME",
                     "latin_name", "latinName", "LATIN_NAME",
                     "valid_name", "validName", "VALID_NAME", 
                     "complete_name", "completeName" ,"COMPLETE_NAME"
                      )

# String matching
# str_which(potential_names, pattern = regex("species|name|scientific", ignore_case = TRUE))
str_which(names(westerband_2022_wdate), pattern = regex("species|name|scientific", ignore_case = TRUE))

# Select the matched column
species <- westerband_2022_wdate |> 
  select(str_which(names(westerband_2022_wdate), pattern = regex("species|name|scientific", ignore_case = TRUE))) 

# Rename as scientificName
species <- species |> 
  rename(raw_scientificName = Species) 
```

#### b - Date information

```{r}
# Select date column
date <- select_if(westerband_2022_wdate, function(x) inherits(x, 'Date'))

# Rename as raw_eventDate
date <- date |> 
  rename(raw_eventDate = Collection_date) 
```

##### Checking dates

What if date information is inputted in other formats e.g 1-Jul-1998, 20-Mar-23, 06-30-2018 (June 30th - North American formatting) 
We will need to split the string up and guess if its a month, day, year base on number of characters and ranges of the column.

Wonder if we can use {pointblank} for these checks

```{r}
# Example 1
date_1 <- tibble(date = c("1-Jul-1998", "1-Aug-1998", "1-Sept-1998", "1-Oct-1998"))
date_1

# Example 2 d/m/yyyy
date_2 <- tibble(date = c("1/7/1998", "1/8/1998", "1/9/1998", "1/10/1998"))
date_2

# Example 3 m.d.yyyy
date_3 <- tibble(date = c("7.1.1998", "8.9.1998", "9.15.1998", "10.27.1998"))
date_3

#Split string by common date seperators - / . 
date_separators <- c("-", "/", "\\.")

# Separate date to guess date format
split_date <- date_1 |> 
  separate_wider_delim(cols = date,
                       delim = regex(paste(date_separators, collapse = "|")),
                       names = c("first", "second", "third"))

# Which column contains letters?
map_lgl(split_date,
    ~any(str_detect(.x, pattern = regex("[:alpha:]")) ))

letters_res <- map_lgl(split_date,
    ~any(str_detect(.x, pattern = regex("[:alpha:]")) ))

# Letters column is likely to be month
# Detect month letter strings
month_letter_pattern <-  c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
                           "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")

str_detect(split_date[letters_res] |> pull() , pattern = regex(paste(month_letter_pattern, collapse = "|"))) |> any()

# Mutate column as month
split_date |> 
  mutate(month = split_date[letters_res] |> pull())

# Which column contains digits?
digit_res <- map_lgl(split_date,
    ~any(str_detect(.x, pattern = regex("[:digit:]")) ))


# How many characters do values in each column have?
map_vec(split_date[which(digit_res)],
        ~ nchar(.x) |> unique())

# Likely year if 4 characters
year_char_test <- map_vec(split_date[which(digit_res)],
        ~ nchar(.x) |> unique() == 4)

split_date[which(year_char_test == TRUE)]

# If digit, convert to numeric
# Test if values are between 1-12
map(split_date[which(digit_res)],
        ~ as.numeric(.x))

map_vec(split_date[which(digit_res)],
    ~ as.numeric(max(.x)) <= 31)

# Check if max is less than 12, if FALSE then its a month
split_date$first |> as.numeric() |> max() > 12
```

#### c - Location information

Should site here be...locationRemarks? or verbatimLocality? 

```{r}
#site, collection_site, location, character, state, country, latitude, longitude

location <- westerband_2022_wdate |> 
  select(str_which(names(westerband_2022), pattern = regex("site|location|state|country|province|latitude|longitude", ignore_case = TRUE))) 

# Rename columns respectively 
location <- location |> 
  rename(raw_decimalLatitude =  Latitude,
         raw_decimaleLongitude = Longitude,
         verbatimLocality = Site)
```

##### Check location information

Presumably the user needs to filter some of these sites out? Some of these are plant genuses e.g Transcontinentalis
Maybe a check box that users can click to include in data? 

```{r}
location$verbatimLocality |> tabyl()
```

### 3) Put seperate datasets together 

Just the bare minimum data here

```{r}
westerband_subset <- bind_cols(species, date, location)
```

### 4) Export as .csv

```{r}
write_csv(westerband_subset, here("output/csv/westerband_subset.csv"))
```

### 5) Meta data template eml.xml "Environmental meta-data"

Currently made for mandatory fields only, template found [here](https://support.ala.org.au/support/solutions/articles/6000261427-sharing-a-dataset-with-the-ala#minimum-fields)

#### .Rmd to .R

```{r}
knitr::purl( here("doc/metadata.Rmd"), output = here("output/script/metadata.R"), documentation = 2)
```

#### .md into R

```{r}
scan_output <- scan(here("doc/westerband_template.md"),
                    what = "character", 
                    sep = "\n", 
                    blank.lines.skip = FALSE)

str(scan_output)

# This format might be better since not every word is separated as a string
rl_output <- readLines(con = here("doc/westerband_template.md")) 

str(rl_output)

# Make as tibble
rl_df <- tibble(input = rl_output)

# Count the # at the start of the string
# Testing the regex pattern
str_subset(rl_df$input, regex("^#"))

# Create grouping variable
rl_df <- rl_df |>
  mutate(group_id = str_detect(input, regex("^#")) |> cumsum())

# Split by group id for now to have a look
split(rl_df, f = rl_df$group_id)

# Concatenate strings below header e.g. see split(rl_df, f = rl_df$group_id)[[11]]
md <- split(rl_df, f = rl_df$group_id)[[11]]

# The element of each list is always the header, we need to concatenate the elements from 2:n
md |> slice(2:nrow(md))

# Take anything below the 1st row, trim the white space or exclude the empty elements and join strings
md |> 
  slice(2:nrow(md)) |> 
  filter(! input == "") |> 
  pull(input) |> 
  paste(collapse="") # Whoa this seemed to work! 

# Create a function to do this
join_user_text <- function(group_df){
  group_df |> 
  slice(2:nrow(group_df)) |>  # Take anything below the 1st row
  filter(! input == "") |>  # Exclude the empty elements of input 
  pull(input) |>  # Isolate column as vector
  paste(collapse="")  #  Join strings
}

# Try in a vectorised way
str_subset(md |> pull(input),
           regex("^#|^$"), negate = TRUE)

join_user_text_vectorised <- function(vec){
  str_subset(vec,
           regex("^#|^$"), negate = TRUE)
}

# Mapping across the group_id
rl_nest <- rl_df |> 
  nest(text = input) |> 
  mutate(joined_str = map(text,
                          ~join_user_text(.x)))

# Create header variable to denote the section the text is from
find_header <- function(group_df){
  # pattern = "(?<=#\\s)(\\w+(?:\\s+\\w+)*(?:\\s+\\*|\\)?)"
  
  pattern = "(?<=#\\s)(.*\\S.*)"

  group_df |> 
    slice(1) |> 
    pull(input) |> 
    str_extract(pattern = pattern)
}

# Unnest 
rl_wrangled <- rl_nest |> 
  mutate(header = map(text,
                      ~find_header(.x))) |> 
  select(group_id, header, joined_str,  text) |> 
  unnest(cols = c(header, joined_str)) |> 
  print(n = 30)

# Trim WS in header
rl_wrangled <- rl_wrangled |> 
  mutate(header = trimws(header, "both"))
```

#### Convert tibble to list

```{r}
x <- rl_wrangled |> 
  select(joined_str)

# Convert into list
list <- as.list(x) |> list_transpose() 

# Set names to match the template
set_names(list, rl_wrangled$header)

# Name need to be split by first name and surname



# Need a look up table with header in md/word doc to match EML.xml
# tibble(md_header = rl_wrangled$header) |> 
#   write_csv(here("output/csv/header_tag_lookup.csv"))




# This is the set structure
template <- list(
  dataset = list(
    alternateIdentifier = "48458dk392-dfkal-b7e4-609",
    alternateIdentifier = "https://collections-test.ala.org.au/public/show/dr860275602765",
    title = "Dataset Name",
    creator = list(
      organizationName = "Organisation Name",
      metadataProvider = "Organisation Name"
    ),
    associatedParty = list(
      organizationName = "Atlas of Living Australia",
      address = list(
        deliveryPoint = "CSIRO Ecosystems Services",
        city = "Canberra",
        administrativeArea = "ACT",
        postalCode = "2601",
        country = "Australia"
      ) ,
      role = "distributor"
    ),
    pubDate = "2022-06-21",
    language = "English",
    abstract = "And then bandicoot from case in point. Lilly pilly cane toad kingfisher. Tasmanian devil lemon myrtle blue-ringed octopus.",
    intellectualRights = list(
      citetitle = "Creative Commons Attribution 4.0 International (CC-BY 4.0)"
    ),
    distribution =list(
      online = ""
    ),
    coverage = "",
    purpose = "",
    contact = list(
      individualName = list(
        givenName = "Jay",
        surName = "Citizen"
      )
    ),
    methods = ""
  ),
  additionalMetadata = list(
    metadata = list(
      gbif = list(
        dateStamp = "2022-06-21T04:45:31",
        hierarchyLevel = "dataset",
        resourceLogoUrl = "https://collections-test.ala.org.au/data/dataProvider/test.png</resourceLogoUrl"
      )
    )
  )
)


```


### 6) Convert meta data R script to XML

R object to list to XML? Possible? Explore

https://xml2.r-lib.org/

A guide to XML documents: https://www.w3schools.com/xml/xml_tree.asp

On the {XML} package: https://stackoverflow.com/questions/57624678/generate-xml-document-in-r

This looks promising too {minixml}: https://coolbutuseless.github.io/2019/09/30/introducing-the-minixml-package-for-creating-xml-documents-in-r/

XML template: 

```
<?xml version="1.0" encoding="utf-8"?>
<eml:eml xmlns:d="eml://ecoinformatics.org/dataset-2.1.0" xmlns:eml="eml://ecoinformatics.org/eml-2.1.1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dc="http://purl.org/dc/terms/" xsi:schemaLocation="eml://ecoinformatics.org/eml-2.1.1 http://rs.gbif.org/schema/eml-gbif-profile/1.1/eml-gbif-profile.xsd" system="ALA-Registry" scope="system" xml:lang="en">
  <dataset>
    <alternateIdentifier>48458dk392-dfkal-b7e4-609</alternateIdentifier>
    <alternateIdentifier>https://collections-test.ala.org.au/public/show/dr860275602765</alternateIdentifier>
    <title xmlns:lang="en">Dataset Name</title>
    <creator>
      <organizationName>Organisation Name</organizationName>
    </creator>
    <metadataProvider>
      <organizationName>Organisation Name</organizationName>
    </metadataProvider>
    <associatedParty>
      <organizationName>Atlas of Living Australia</organizationName>
      <address>
        <deliveryPoint>CSIRO Ecosystems Services</deliveryPoint>
        <city>Canberra</city>
        <administrativeArea>ACT</administrativeArea>
        <postalCode>2601</postalCode>
        <country>Australia</country>
      </address>
      <electronicMailAddress />
      <role>distributor</role>
    </associatedParty>
    <pubDate>2022-06-21</pubDate>
    <language>English</language>
    <abstract>
    <para>And then bandicoot from case in point. Lilly pilly cane toad kingfisher. Tasmanian devil lemon myrtle blue-ringed octopus.</para>
</abstract>
    <intellectualRights>
      <para>
        <ulink url="https://creativecommons.org/licenses/by/4.0/">
          <citetitle>Creative Commons Attribution 4.0 International (CC-BY 4.0)</citetitle>
        </ulink>
      </para>
    </intellectualRights>
    <distribution>
      <online>
        <url function="information">https://collections-test.ala.org.au/public/show/dr860275602765</url>
      </online>
    </distribution>
    <coverage />
    <purpose>
      <para></para>
    </purpose>
    <contact>
      <individualName>
        <givenName>Jay</givenName>
        <surName>Citizen</surName>
      </individualName>
    </contact>
    <methods />
  </dataset>
  <additionalMetadata>
    <metadata>
      <gbif>
        <dateStamp>2022-06-21T04:45:31</dateStamp>
        <hierarchyLevel>dataset</hierarchyLevel>
        <resourceLogoUrl>https://collections-test.ala.org.au/data/dataProvider/test.png</resourceLogoUrl>
      </gbif>
    </metadata>
  </additionalMetadata>
</eml:eml>

```

Try reproduce the template above with {xml2}

```{r}
# install.packages("xml2")
library(xml2)

# Create a new XML document with root
eml <- xml_new_root(version="1.0", encoding="utf-8",
                    "eml") 

eml # How do I preview the document? 

# Add an element/a parent node called dataset
eml <- eml |> xml_add_parent("dataset")

eml

# Add a child element
eml <- eml |> xml_add_child("alternateIdentifier") # How do I give this a value?

eml # How do I continually build on a document? 

```

Try reproduce the template above with {EML}

Not sure how to: 
- I think this is the namespace...how do I change it?
- not get alphabetical sort with tags
- Insert paragraphs
- assign attributes? `<ulink url="https://creativecommons.org/licenses/by/4.0/">`


Use `list(online = "") `for empty cells
```{r}
# install.packages("EML")
library(EML)
library(here)

eml <- list(
  dataset = list(
    alternateIdentifier = "48458dk392-dfkal-b7e4-609",
    alternateIdentifier = "https://collections-test.ala.org.au/public/show/dr860275602765",
    title = "Dataset Name",
    creator = list(
      organizationName = "Organisation Name",
      metadataProvider = "Organisation Name"
    ),
    associatedParty = list(
      organizationName = "Atlas of Living Australia",
      address = list(
        deliveryPoint = "CSIRO Ecosystems Services",
        city = "Canberra",
        administrativeArea = "ACT",
        postalCode = "2601",
        country = "Australia"
      ) ,
      role = "distributor"
    ),
    pubDate = "2022-06-21",
    language = "English",
    abstract = "And then bandicoot from case in point. Lilly pilly cane toad kingfisher. Tasmanian devil lemon myrtle blue-ringed octopus.",
    intellectualRights = list(
      citetitle = "Creative Commons Attribution 4.0 International (CC-BY 4.0)"
    ),
    distribution =list(
      online = ""
    ),
    coverage = "",
    purpose = "",
    contact = list(
      individualName = list(
        givenName = "Jay",
        surName = "Citizen"
      )
    ),
    methods = ""
  ),
  additionalMetadata = list(
    metadata = list(
      gbif = list(
        dateStamp = "2022-06-21T04:45:31",
        hierarchyLevel = "dataset",
        resourceLogoUrl = "https://collections-test.ala.org.au/data/dataProvider/test.png</resourceLogoUrl"
      )
    )
  )
)

write_eml(eml, 
          here("output/eml/ex_eml"),
          )
```


##### Name space

`<title xmlns:lang="en">` this syntax here has something to do with the "namespace"

ALA version

```
<eml:eml xmlns:d="eml://ecoinformatics.org/dataset-2.1.0" xmlns:eml="eml://ecoinformatics.org/eml-2.1.1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dc="http://purl.org/dc/terms/" xsi:schemaLocation="eml://ecoinformatics.org/eml-2.1.1 http://rs.gbif.org/schema/eml-gbif-profile/1.1/eml-gbif-profile.xsd" system="ALA-Registry" scope="system" xml:lang="en">
```

EML package version

```
<eml:eml xmlns:eml="https://eml.ecoinformatics.org/eml-2.2.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:stmml="http://www.xml-cml.org/schema/stmml-1.2" packageId="250cd7cf-e886-4519-875d-f17b0f5a0650" system="uuid" xsi:schemaLocation="https://eml.ecoinformatics.org/eml-2.2.0 https://eml.ecoinformatics.org/eml-2.2.0/eml.xsd">
```

```{r}
library(xml2)

eml <- read_xml(here("output/eml/ex_eml"))

test <- xml_set_namespace(eml, 
                  prefix = "system",
                  uri = "ALA-Register")



xml_ns(eml)
xml_ns(test)
?xml_set_namespace

```

##### Attributes

```{r}
em
```

### Creating meta.xml field (mapping fields to fields)

This step is a mystery atm
occurrence.csv is the user supplied data
NB: Peggy has Python matching occurrence cols to fields in meta.xml

```
<?xml version="1.0" ?>
<archive xmlns="http://rs.tdwg.org/dwc/text/" metadata="eml.xml">
  <core encoding="UTF-8" rowType="http://rs.tdwg.org/dwc/terms/Occurrence" fieldsTerminatedBy="," linesTerminatedBy="\r\n" fieldsEnclosedBy="&quot;" ignoreHeaderLines="1">
    <files>
      <location>occurrence.csv</location>
    </files>
    <id index="0"/>
    <field index="1" term="http://rs.tdwg.org/dwc/terms/catalogNumber"/>
    <field index="2" term="http://rs.tdwg.org/dwc/terms/taxonID"/>
    <field index="3" term="http://rs.tdwg.org/dwc/terms/scientificName"/>
    <field index="4" term="http://rs.tdwg.org/dwc/terms/vernacularName"/>
    <field index="5" term="http://rs.tdwg.org/dwc/terms/occurrenceID"/>
    <field index="6" term="http://rs.tdwg.org/dwc/terms/decimalLatitude"/>
    <field index="7" term="http://rs.tdwg.org/dwc/terms/decimalLongitude"/>
    <field index="8" term="http://rs.tdwg.org/dwc/terms/verbatimElevation"/>
    <field index="9" term="http://rs.tdwg.org/dwc/terms/recordedBy"/>
    <field index="10" term="http://rs.tdwg.org/dwc/terms/individualCount"/>
    <field index="11" term="http://rs.tdwg.org/dwc/terms/eventDate"/>
    <field index="12" term="http://rs.tdwg.org/dwc/terms/occurrenceRemarks"/>
    <field index="13" term="http://rs.tdwg.org/dwc/terms/identifiedBy"/>
    <field index="14" term="http://rs.tdwg.org/dwc/terms/dateIdentified"/>
    <field index="15" term="http://rs.tdwg.org/dwc/terms/locality"/>
    <field index="16" term="http://rs.tdwg.org/dwc/terms/stateProvince"/>
    <field index="17" term="http://rs.tdwg.org/dwc/terms/basisOfRecord"/>
    <field index="18" term="http://rs.tdwg.org/dwc/terms/taxonRemarks"/>
    <field index="19" term="http://rs.tdwg.org/dwc/terms/dynamicProperties"/>
  </core>
  <extension encoding="UTF-8" rowType="http://rs.gbif.org/terms/1.0/Multimedia" fieldsTerminatedBy="," linesTerminatedBy="\r\n" fieldsEnclosedBy="&quot;" ignoreHeaderLines="1">
    <files>
      <location>multimedia.csv</location>
    </files>
    <coreid index="0"/>
    <field index="1" term="http://rs.tdwg.org/dwc/terms/catalogNumber"/>
    <field index="2" term="http://purl.org/dc/terms/identifier"/>
    <field index="3" term="captureDevice"/>
    <field index="4" term="http://purl.org/dc/terms/type"/>
    <field index="5" term="http://purl.org/dc/terms/format"/>
  </extension>
</archive>
```

```{r}

```



### 7) Zip it all together and ship it to Data team
Is email the best way? 
Size requirement:

One-off complete datasets under 10MB (compressed) can simply be emailed to the ALA at data_management@ala.org.au.

For a large dataset (over 10MB) or where there will be regular updates, please contact the team at the same address to arrange machine-to-machine delivery. 